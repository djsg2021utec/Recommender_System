{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPhxEftEt8Wh+Zx1vi9vd4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djsg2021utec/Recommender_System/blob/main/Copia_de_ViVIT_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsHcmerqsv_K"
      },
      "outputs": [],
      "source": [
        "%pip install torch torchvision -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNZsGFjbtENG",
        "outputId": "09e2aad0-a5c7-497b-b981-711717c750d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/drv-agwl/ViViT-pytorch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1358l29t5HV",
        "outputId": "5de9f2f7-299c-4fae-c282-2cf5d0840450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ViViT-pytorch'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 54 (delta 18), reused 13 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (54/54), 282.68 KiB | 6.89 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ViViT-pytorch/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNemTXLivYfU",
        "outputId": "33500514-84d3-48c4-b94e-42a93a9a8ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ViViT-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extraer los videos"
      ],
      "metadata": {
        "id": "U4resr--RHFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enlace del repositorio donde está alojandos los datos\n",
        "# https://github.com/mchengny/RWF2000-Video-Database-for-Violence-Detection\n",
        "%%capture\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import os\n",
        "from base64 import b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "from matplotlib import pyplot as plt\n",
        "import glob\n",
        "from random import shuffle\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "#%pip install gdown (Descomentar si requiere instalar)\n",
        "\n",
        "# ********************************************************************\n",
        "# Descargando los fragmentos del archivo ZIP de la data RWF-2000.zip\n",
        "# ********************************************************************\n",
        "download_links = [\n",
        "    \"https://drive.google.com/uc?id=1nQ9IR3cGc4NEDOXhPQ89id8je8Uj2VUc\",\n",
        "    \"https://drive.google.com/uc?id=1w9G_Z7gkXZzK4DImdI8wanyjs22fQARO\",\n",
        "    \"https://drive.google.com/uc?id=15LhjavoUsLS01CPkc3qav0rJxBc9d4nl\"\n",
        "]\n",
        "\n",
        "for link in tqdm(download_links, desc=\"Descargando fragmentos\"):\n",
        "    !gdown {link}\n",
        "# ********************************************************************\n",
        "# Juntando los fragmentos del archivo ZIP de la data RWF-2000.zip\n",
        "# ********************************************************************\n",
        "!cat RWF-2000.zip.001 RWF-2000.zip.002 RWF-2000.zip.003 > RWF-2000.zip\n",
        "\n",
        "# Eliminando los fragmentos\n",
        "for fragment in tqdm([\"RWF-2000.zip.001\", \"RWF-2000.zip.002\", \"RWF-2000.zip.003\"], desc=\"Eliminando fragmentos\"):\n",
        "    !rm /content/{fragment}\n",
        "\n",
        "# Descomprimiendo los archivos en el directorio RWF-2000\n",
        "!unzip \"/content/RWF-2000.zip\" -d \"/content/\"\n",
        "\n",
        "# Eliminando RWF-2000.zip\n",
        "!rm /content/RWF-2000.zip\n",
        "\n",
        "# Asegurar que la memoria RAM se liberó\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "time.sleep(10)"
      ],
      "metadata": {
        "id": "6Nw8e2k3RLnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ******************************************************************\n",
        "# Se crea un dataframe para manejar fácilmente los datos de RWF-2000\n",
        "# ******************************************************************\n",
        "carpeta = 'RWF-2000'\n",
        "lista_carpetas_avi = [\n",
        "    {'ruta': f'/content/{carpeta}/train/Fight', 'data': 'train', 'etiqueta':'Fight'},\n",
        "    {'ruta': f'/content/{carpeta}/train/NonFight', 'data': 'train', 'etiqueta':'NonFight'},\n",
        "    {'ruta': f'/content/{carpeta}/val/Fight', 'data': 'val', 'etiqueta':'Fight'},\n",
        "    {'ruta': f'/content/{carpeta}/val/NonFight', 'data': 'val', 'etiqueta':'NonFight'}\n",
        "]\n",
        "lista_archivos_avi = []\n",
        "for carpeta in lista_carpetas_avi:\n",
        "  ruta_carpeta=carpeta['ruta']\n",
        "  tipo_data =carpeta['data']\n",
        "  etiqueta_data =carpeta['etiqueta']\n",
        "  for filename in os.listdir(ruta_carpeta):\n",
        "      if filename.endswith(\".avi\"):\n",
        "        registro_archivo = {'ruta': f'{ruta_carpeta}/{filename}', 'data': f'{tipo_data}', 'etiqueta':f'{etiqueta_data}'}\n",
        "        lista_archivos_avi.append(registro_archivo)\n"
      ],
      "metadata": {
        "id": "-QkCcT4TXq8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos_RWF2000_df = pd.DataFrame(lista_archivos_avi)\n",
        "videos_RWF2000_df.describe()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "cm9tPgckXuwJ",
        "outputId": "3e0a9c1e-4ccd-4a08-968f-5c9e6a6a2908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   ruta   data etiqueta\n",
              "count                                              2000   2000     2000\n",
              "unique                                             2000      2        2\n",
              "top     /content/RWF-2000/train/Fight/X6V5o-uCYF4_4.avi  train    Fight\n",
              "freq                                                  1   1600     1000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-357b7102-5b84-4acc-8041-f412faa51667\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ruta</th>\n",
              "      <th>data</th>\n",
              "      <th>etiqueta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>/content/RWF-2000/train/Fight/X6V5o-uCYF4_4.avi</td>\n",
              "      <td>train</td>\n",
              "      <td>Fight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>1600</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-357b7102-5b84-4acc-8041-f412faa51667')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-357b7102-5b84-4acc-8041-f412faa51667 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-357b7102-5b84-4acc-8041-f412faa51667');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f91264e0-ff26-4af4-bb89-0d1c7062ed98\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f91264e0-ff26-4af4-bb89-0d1c7062ed98')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f91264e0-ff26-4af4-bb89-0d1c7062ed98 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# **********************************************************************\n",
        "# Se toma una muestra con una fracción de los datos del dataframe\n",
        "# **********************************************************************\n",
        "\n",
        "# Función para obtener un subconjunto aleatorio del DataFrame\n",
        "def grupo_de_muestras(group, frac=0.1):\n",
        "    return group.sample(frac=frac)\n",
        "\n",
        "# Dividir el DataFrame según las variables 'etapa' y 'etiqueta' y aplicar la función grupo_de_muestras\n",
        "muestra_RWF2000_df = videos_RWF2000_df.groupby(['data', 'etiqueta']).apply(grupo_de_muestras).reset_index(drop=True)\n",
        "# Se elimina una variable que tiene muchas variables\n",
        "del videos_RWF2000_df\n",
        "\n",
        "muestra_RWF2000_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "xsF0DBc3YI-z",
        "outputId": "d301eb2b-190b-489c-f765-aa87df20d387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   ruta   data etiqueta\n",
              "count                                               200    200      200\n",
              "unique                                              200      2        2\n",
              "top     /content/RWF-2000/train/Fight/BpargJW29Wo_0.avi  train    Fight\n",
              "freq                                                  1    160      100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f412c21b-ca09-4399-a78a-a77b912ef9de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ruta</th>\n",
              "      <th>data</th>\n",
              "      <th>etiqueta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>200</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>/content/RWF-2000/train/Fight/BpargJW29Wo_0.avi</td>\n",
              "      <td>train</td>\n",
              "      <td>Fight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f412c21b-ca09-4399-a78a-a77b912ef9de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f412c21b-ca09-4399-a78a-a77b912ef9de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f412c21b-ca09-4399-a78a-a77b912ef9de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-505366c0-6293-4683-b0d8-b4e9ecdd4b51\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-505366c0-6293-4683-b0d8-b4e9ecdd4b51')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-505366c0-6293-4683-b0d8-b4e9ecdd4b51 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### No es necesario hacer la conversión a .mp4 porque se puede usar directamente el archivo .avi para construir los tensores"
      ],
      "metadata": {
        "id": "_1CcRdj1BGH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea una función para que convierta un .avi a .mp4 en la misma carpeta con la condición que existan frames\n",
        "\n",
        "def volver_crear_mp4(ruta):\n",
        "  path = ruta\n",
        "  if os.path.exists(ruta):\n",
        "    print(\"Se elimina el archivo: \",path)\n",
        "    os.remove(ruta)\n",
        "    time.sleep(4)\n",
        "  root = os.path.dirname(path)\n",
        "  nombre=path.split('/')[-1:][0].split('.')[0]\n",
        "  ruta_archivo_avi=f'{root}/{nombre}.avi'\n",
        "  ruta_archivo_mp4=f'{root}/{nombre}'\n",
        "\n",
        "  os.popen(\"ffmpeg -i '{input}' -ac 2 -b:v 2000k -c:a aac -c:v libx264 -b:a 160k -vprofile high -bf 0 -strict experimental -f mp4 '{output}.mp4'\".format(input=ruta_archivo_avi, output=ruta_archivo_mp4))\n",
        "  if os.path.exists(f'{ruta_archivo_mp4}.mp4'):\n",
        "    print(\"Se vuelve a crear el archivo: \",path)\n",
        "    time.sleep(10)"
      ],
      "metadata": {
        "id": "FEkrXjUKZDh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Ruta del archivo de video\n",
        "video_paths = list(muestra_RWF2000_df['ruta'])\n",
        "\n",
        "videos = []\n",
        "for video_path in video_paths:\n",
        "  # Abrir el video\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "  # Obtener las características del video\n",
        "  frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "  num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  duration = num_frames / fps\n",
        "\n",
        "  # Definir la resolución y el número de canales deseados\n",
        "  target_resolution = (224, 224)\n",
        "  target_channels = 3\n",
        "\n",
        "  # Inicializar una lista para almacenar los frames redimensionados\n",
        "  frames = []\n",
        "\n",
        "  while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "          break\n",
        "\n",
        "      # Número de canales deseado\n",
        "      if frame.shape[-1] != target_channels:\n",
        "          frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convertir a RGB si es necesario\n",
        "\n",
        "      # Redimensionar el frame a la resolución deseada usando tf.image.resize\n",
        "      frame = tf.image.resize(frame, target_resolution)\n",
        "\n",
        "      # Convertir el frame a tensor y agregarlo a la lista\n",
        "      frame_tensor = tf.convert_to_tensor(frame, dtype=tf.float32) / 255.0\n",
        "      frames.append(frame_tensor)\n",
        "\n",
        "  # Apilar los frames en un tensor 4D (frames, alto, ancho, canales)\n",
        "  video_tensor = tf.stack(frames, axis=0)\n",
        "  video_tensor = tf.transpose(video_tensor, [3, 0, 1, 2])\n",
        "  video_tensor = torch.tensor(video_tensor.numpy())\n",
        "  videos.append(video_tensor)\n",
        "  # Liberar los recursos\n",
        "  cap.release()\n",
        "\n",
        "tensor_torch = torch.stack(videos, dim=0)\n",
        "\n",
        "# Imprimir las dimensiones del tensor resultante\n",
        "print(\"Dimensiones del tensor resultante:\", tensor_torch.shape)\n"
      ],
      "metadata": {
        "id": "rS_iPflGEJHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Construir los Labels\n",
        "# Lista de etiquetas\n",
        "labels = list(muestra_RWF2000_df['etiqueta'])\n",
        "\n",
        "# Crear un diccionario de mapeo de etiquetas a valores binarios (1 y 0)\n",
        "label_map = {'Fight': 1, 'NonFight': 0}\n",
        "\n",
        "# Convertir las etiquetas a valores binarios usando el mapeo\n",
        "binary_labels = [label_map[label] for label in labels]\n",
        "\n",
        "# Crear un tensor de PyTorch a partir de la lista de valores binarios\n",
        "tensor_labels = torch.tensor(binary_labels, dtype=torch.float32)\n",
        "\n",
        "# Imprimir el tensor resultante\n",
        "tensor_labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNtFM50OMvSO",
        "outputId": "1d7cb72e-01ad-48ea-f157-ab6a8e9279a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_labels = tensor_labels.to(torch.long)\n",
        "tensor_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES3CJC3TNso8",
        "outputId": "2fc724b8-3686-426e-ea81-3917acabbda9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenar el modelo"
      ],
      "metadata": {
        "id": "YMGOhH50RMNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install einops\n",
        "from torch import nn, einsum\n",
        "import torch\n",
        "from einops.layers.torch import Rearrange\n",
        "from einops import rearrange, repeat\n",
        "\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "\n",
        "class FSAttention(nn.Module):\n",
        "    \"\"\"Factorized Self-Attention\"\"\"\n",
        "\n",
        "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.attend = nn.Softmax(dim=-1)\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, n, _, h = *x.shape, self.heads\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), qkv)\n",
        "\n",
        "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "\n",
        "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        return self.to_out(out)\n",
        "\n",
        "\n",
        "class FDAttention(nn.Module):\n",
        "    \"\"\"Factorized Dot-product Attention\"\"\"\n",
        "\n",
        "    def __init__(self, dim, nt, nh, nw, heads=8, dim_head=64, dropout=0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.nt = nt\n",
        "        self.nh = nh\n",
        "        self.nw = nw\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.attend = nn.Softmax(dim=-1)\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, n, d, h = *x.shape, self.heads\n",
        "\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), qkv)\n",
        "        qs, qt = q.chunk(2, dim=1)\n",
        "        ks, kt = k.chunk(2, dim=1)\n",
        "        vs, vt = v.chunk(2, dim=1)\n",
        "\n",
        "        # Attention over spatial dimension\n",
        "        qs = qs.view(b, h // 2, self.nt, self.nh * self.nw, -1)\n",
        "        ks, vs = ks.view(b, h // 2, self.nt, self.nh * self.nw, -1), vs.view(b, h // 2, self.nt, self.nh * self.nw, -1)\n",
        "        spatial_dots = einsum('b h t i d, b h t j d -> b h t i j', qs, ks) * self.scale\n",
        "        sp_attn = self.attend(spatial_dots)\n",
        "        spatial_out = einsum('b h t i j, b h t j d -> b h t i d', sp_attn, vs)\n",
        "\n",
        "        # Attention over temporal dimension\n",
        "        qt = qt.view(b, h // 2, self.nh * self.nw, self.nt, -1)\n",
        "        kt, vt = kt.view(b, h // 2, self.nh * self.nw, self.nt, -1), vt.view(b, h // 2, self.nh * self.nw, self.nt, -1)\n",
        "        temporal_dots = einsum('b h s i d, b h s j d -> b h s i j', qt, kt) * self.scale\n",
        "        temporal_attn = self.attend(temporal_dots)\n",
        "        temporal_out = einsum('b h s i j, b h s j d -> b h s i d', temporal_attn, vt)\n",
        "\n",
        "        # return self.to_out(out)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class FSATransformerEncoder(nn.Module):\n",
        "    \"\"\"Factorized Self-Attention Transformer Encoder\"\"\"\n",
        "\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, nt, nh, nw, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        self.nt = nt\n",
        "        self.nh = nh\n",
        "        self.nw = nw\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList(\n",
        "                [PreNorm(dim, FSAttention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
        "                 PreNorm(dim, FSAttention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
        "                 PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
        "                 ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        b = x.shape[0]\n",
        "        x = torch.flatten(x, start_dim=0, end_dim=1)  # extract spatial tokens from x\n",
        "\n",
        "        for sp_attn, temp_attn, ff in self.layers:\n",
        "            sp_attn_x = sp_attn(x) + x  # Spatial attention\n",
        "\n",
        "            # Reshape tensors for temporal attention\n",
        "            sp_attn_x = sp_attn_x.chunk(b, dim=0)\n",
        "            sp_attn_x = [temp[None] for temp in sp_attn_x]\n",
        "            sp_attn_x = torch.cat(sp_attn_x, dim=0).transpose(1, 2)\n",
        "            sp_attn_x = torch.flatten(sp_attn_x, start_dim=0, end_dim=1)\n",
        "\n",
        "            temp_attn_x = temp_attn(sp_attn_x) + sp_attn_x  # Temporal attention\n",
        "\n",
        "            x = ff(temp_attn_x) + temp_attn_x  # MLP\n",
        "\n",
        "            # Again reshape tensor for spatial attention\n",
        "            x = x.chunk(b, dim=0)\n",
        "            x = [temp[None] for temp in x]\n",
        "            x = torch.cat(x, dim=0).transpose(1, 2)\n",
        "            x = torch.flatten(x, start_dim=0, end_dim=1)\n",
        "\n",
        "        # Reshape vector to [b, nt*nh*nw, dim]\n",
        "        x = x.chunk(b, dim=0)\n",
        "        x = [temp[None] for temp in x]\n",
        "        x = torch.cat(x, dim=0)\n",
        "        x = torch.flatten(x, start_dim=1, end_dim=2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class FDATransformerEncoder(nn.Module):\n",
        "    \"\"\"Factorized Dot-product Attention Transformer Encoder\"\"\"\n",
        "\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, nt, nh, nw, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        self.nt = nt\n",
        "        self.nh = nh\n",
        "        self.nw = nw\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(\n",
        "                PreNorm(dim, FDAttention(dim, nt, nh, nw, heads=heads, dim_head=dim_head, dropout=dropout)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for attn in self.layers:\n",
        "            x = attn(x) + x\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class ViViTBackbone(nn.Module):\n",
        "    \"\"\" Model-3 backbone of ViViT \"\"\"\n",
        "\n",
        "    def __init__(self, t, h, w, patch_t, patch_h, patch_w, num_classes, dim, depth, heads, mlp_dim, dim_head=3,\n",
        "                 channels=3, mode='tubelet', device='cuda', emb_dropout=0., dropout=0., model=3):\n",
        "        super().__init__()\n",
        "\n",
        "        assert t % patch_t == 0 and h % patch_h == 0 and w % patch_w == 0, \"Video dimensions should be divisible by \" \\\n",
        "                                                                           \"tubelet size \"\n",
        "\n",
        "        self.T = t\n",
        "        self.H = h\n",
        "        self.W = w\n",
        "        self.channels = channels\n",
        "        self.t = patch_t\n",
        "        self.h = patch_h\n",
        "        self.w = patch_w\n",
        "        self.mode = mode\n",
        "        self.device = device\n",
        "\n",
        "        self.nt = self.T // self.t\n",
        "        self.nh = self.H // self.h\n",
        "        self.nw = self.W // self.w\n",
        "\n",
        "        tubelet_dim = self.t * self.h * self.w * channels\n",
        "\n",
        "        self.to_tubelet_embedding = nn.Sequential(\n",
        "            Rearrange('b c (t pt) (h ph) (w pw) -> b t (h w) (pt ph pw c)', pt=self.t, ph=self.h, pw=self.w),\n",
        "            nn.Linear(tubelet_dim, dim)\n",
        "        )\n",
        "\n",
        "        # repeat same spatial position encoding temporally\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, 1, self.nh * self.nw, dim)).repeat(1, self.nt, 1, 1)\n",
        "\n",
        "        self.dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        if model == 3:\n",
        "            self.transformer = FSATransformerEncoder(dim, depth, heads, dim_head, mlp_dim,\n",
        "                                                     self.nt, self.nh, self.nw, dropout)\n",
        "        elif model == 4:\n",
        "            assert heads % 2 == 0, \"Number of heads should be even\"\n",
        "            self.transformer = FDATransformerEncoder(dim, depth, heads, dim_head, mlp_dim,\n",
        "                                                     self.nt, self.nh, self.nw, dropout)\n",
        "\n",
        "        self.to_latent = nn.Identity()\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" x is a video: (b, C, T, H, W) \"\"\"\n",
        "\n",
        "        tokens = self.to_tubelet_embedding(x)\n",
        "\n",
        "        tokens += self.pos_embedding.to(device)\n",
        "        tokens = self.dropout(tokens)\n",
        "\n",
        "        x = self.transformer(tokens)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        x = self.to_latent(x)\n",
        "        return self.mlp_head(x)\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     device = torch.device('cuda')\n",
        "#     x = torch.rand(32, 3, 32, 64, 64).to(device)\n",
        "\n",
        "#     vivit = ViViTBackbone(32, 64, 64, 8, 4, 4, 10, 512, 6, 10, 8, model=3).to(device)\n",
        "#     out = vivit(x)\n",
        "#     print(out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHuJBh9HAR17",
        "outputId": "e3925b16-a42b-4e13-e221-bb554e270aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "# Configuración del modelo y del dispositivo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "v = ViViTBackbone(\n",
        "    t=150,\n",
        "    h=224,\n",
        "    w=224,\n",
        "    patch_t=30,\n",
        "    patch_h=28,\n",
        "    patch_w=28,\n",
        "    num_classes=2,  # Solo hay 2 clases: violencia y no violencia\n",
        "    dim=224,\n",
        "    depth=6,\n",
        "    heads=10,\n",
        "    mlp_dim=5,\n",
        "    model=3\n",
        ").to(device)\n",
        "\n",
        "\n",
        "labels = tensor_labels  # 0 para \"no violencia\", 1 para \"violencia\"\n",
        "videos = tensor_torch\n",
        "\n",
        "# Dividir en entrenamiento y prueba\n",
        "train_data, test_data = random_split(TensorDataset(videos, labels), [16, 4])\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32)\n",
        "\n",
        "# Función de pérdida y optimizador\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(v.parameters(), lr=0.001)\n",
        "\n",
        "# Entrenamiento\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    v.train()\n",
        "    for videos_batch, labels_batch in train_loader:\n",
        "        videos_batch, labels_batch = videos_batch.to(device), labels_batch.to(device)\n",
        "\n",
        "        # Propagación hacia adelante\n",
        "        predictions = v(videos_batch)\n",
        "        loss = criterion(predictions, labels_batch)\n",
        "\n",
        "        # Propagación hacia atrás y optimización\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluación\n",
        "v.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for videos_batch, labels_batch in test_loader:\n",
        "        videos_batch, labels_batch = videos_batch.to(device), labels_batch.to(device)\n",
        "        predictions = v(videos_batch)\n",
        "        _, predicted = torch.max(predictions.data, 1)\n",
        "        total += labels_batch.size(0)\n",
        "        correct += (predicted == labels_batch).sum().item()\n",
        "\n",
        "print(f\"Accuracy of the model on the test videos: {100 * correct / total}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxP1YUfKKIpB",
        "outputId": "42a6a33c-4f85-4387-c8c4-6a0ffa204db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.7376\n",
            "Epoch [2/10], Loss: 3.0891\n",
            "Epoch [3/10], Loss: 2.6735\n",
            "Epoch [4/10], Loss: 2.2947\n",
            "Epoch [5/10], Loss: 1.9440\n",
            "Epoch [6/10], Loss: 1.6192\n",
            "Epoch [7/10], Loss: 1.3241\n",
            "Epoch [8/10], Loss: 1.0683\n",
            "Epoch [9/10], Loss: 0.8671\n",
            "Epoch [10/10], Loss: 0.7376\n",
            "Accuracy of the model on the test videos: 25.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "videos.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1WbGaqbQheq",
        "outputId": "20459ada-d9c3-45a6-f4c4-ebc3fb3cfccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([120, 3, 32, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIKYLiRfNUYE",
        "outputId": "cb0a12d5-5fe7-49a0-c4d4-6b3a065d3d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Fight',\n",
              " 'Fight',\n",
              " 'Fight',\n",
              " 'Fight',\n",
              " 'Fight',\n",
              " 'Fight',\n",
              " 'Fight',\n",
              " 'Fight',\n",
              " 'NonFight',\n",
              " 'NonFight',\n",
              " 'NonFight',\n",
              " 'NonFight',\n",
              " 'NonFight',\n",
              " 'NonFight',\n",
              " 'NonFight',\n",
              " 'NonFight',\n",
              " 'Fight',\n",
              " 'Fight',\n",
              " 'NonFight',\n",
              " 'NonFight']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head *  heads\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, n, _, h = *x.shape, self.heads\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
        "\n",
        "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
        "\n",
        "        attn = dots.softmax(dim=-1)\n",
        "\n",
        "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out =  self.to_out(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ReAttention(nn.Module):\n",
        "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head *  heads\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "\n",
        "        self.reattn_weights = nn.Parameter(torch.randn(heads, heads))\n",
        "\n",
        "        self.reattn_norm = nn.Sequential(\n",
        "            Rearrange('b h i j -> b i j h'),\n",
        "            nn.LayerNorm(heads),\n",
        "            Rearrange('b i j h -> b h i j')\n",
        "        )\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, n, _, h = *x.shape, self.heads\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
        "\n",
        "        # attention\n",
        "\n",
        "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
        "        attn = dots.softmax(dim=-1)\n",
        "\n",
        "        # re-attention\n",
        "\n",
        "        attn = einsum('b h i j, h g -> b g i j', attn, self.reattn_weights)\n",
        "        attn = self.reattn_norm(attn)\n",
        "\n",
        "        # aggregate and out\n",
        "\n",
        "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out =  self.to_out(out)\n",
        "        return out\n",
        "\n",
        "class LeFF(nn.Module):\n",
        "\n",
        "    def __init__(self, dim = 192, scale = 4, depth_kernel = 3):\n",
        "        super().__init__()\n",
        "\n",
        "        scale_dim = dim*scale\n",
        "        self.up_proj = nn.Sequential(nn.Linear(dim, scale_dim),\n",
        "                                    Rearrange('b n c -> b c n'),\n",
        "                                    nn.BatchNorm1d(scale_dim),\n",
        "                                    nn.GELU(),\n",
        "                                    Rearrange('b c (h w) -> b c h w', h=14, w=14)\n",
        "                                    )\n",
        "\n",
        "        self.depth_conv =  nn.Sequential(nn.Conv2d(scale_dim, scale_dim, kernel_size=depth_kernel, padding=1, groups=scale_dim, bias=False),\n",
        "                          nn.BatchNorm2d(scale_dim),\n",
        "                          nn.GELU(),\n",
        "                          Rearrange('b c h w -> b (h w) c', h=14, w=14)\n",
        "                          )\n",
        "\n",
        "        self.down_proj = nn.Sequential(nn.Linear(scale_dim, dim),\n",
        "                                    Rearrange('b n c -> b c n'),\n",
        "                                    nn.BatchNorm1d(dim),\n",
        "                                    nn.GELU(),\n",
        "                                    Rearrange('b c n -> b n c')\n",
        "                                    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.up_proj(x)\n",
        "        x = self.depth_conv(x)\n",
        "        x = self.down_proj(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class LCAttention(nn.Module):\n",
        "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head *  heads\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, n, _, h = *x.shape, self.heads\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
        "        q = q[:, :, -1, :].unsqueeze(2) # Only Lth element use as query\n",
        "\n",
        "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
        "\n",
        "        attn = dots.softmax(dim=-1)\n",
        "\n",
        "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out =  self.to_out(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "857CPsM__3V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "import numpy as np\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
        "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x) + x\n",
        "            x = ff(x) + x\n",
        "        return self.norm(x)\n",
        "\n",
        "\n",
        "\n",
        "class ViViT(nn.Module):\n",
        "    def __init__(self, image_size, patch_size, num_classes, num_frames, dim = 192, depth = 4, heads = 3, pool = 'cls', in_channels = 3, dim_head = 64, dropout = 0.,\n",
        "                 emb_dropout = 0., scale_dim = 4, ):\n",
        "        super().__init__()\n",
        "\n",
        "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "\n",
        "\n",
        "        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        patch_dim = in_channels * patch_size ** 2\n",
        "        self.to_patch_embedding = nn.Sequential(\n",
        "            Rearrange('b t c (h p1) (w p2) -> b t (h w) (p1 p2 c)', p1 = patch_size, p2 = patch_size),\n",
        "            nn.Linear(patch_dim, dim),\n",
        "        )\n",
        "\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_frames, num_patches + 1, dim))\n",
        "        self.space_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.space_transformer = Transformer(dim, depth, heads, dim_head, dim*scale_dim, dropout)\n",
        "\n",
        "        self.temporal_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.temporal_transformer = Transformer(dim, depth, heads, dim_head, dim*scale_dim, dropout)\n",
        "\n",
        "        self.dropout = nn.Dropout(emb_dropout)\n",
        "        self.pool = pool\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.to_patch_embedding(x)\n",
        "        b, t, n, _ = x.shape\n",
        "\n",
        "        cls_space_tokens = repeat(self.space_token, '() n d -> b t n d', b = b, t=t)\n",
        "        x = torch.cat((cls_space_tokens, x), dim=2)\n",
        "        x += self.pos_embedding[:, :, :(n + 1)]\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = rearrange(x, 'b t n d -> (b t) n d')\n",
        "        x = self.space_transformer(x)\n",
        "        x = rearrange(x[:, 0], '(b t) ... -> b t ...', b=b)\n",
        "\n",
        "        cls_temporal_tokens = repeat(self.temporal_token, '() n d -> b n d', b=b)\n",
        "        x = torch.cat((cls_temporal_tokens, x), dim=1)\n",
        "\n",
        "        x = self.temporal_transformer(x)\n",
        "\n",
        "\n",
        "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
        "\n",
        "        return self.mlp_head(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    img = torch.ones([1, 16, 3, 224, 224]).cuda()\n",
        "\n",
        "    model = ViViT(224, 16, 100, 16).cuda()\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    parameters = sum([np.prod(p.size()) for p in parameters]) / 1_000_000\n",
        "    print('Trainable Parameters: %.3fM' % parameters)\n",
        "\n",
        "    out = model(img)\n",
        "\n",
        "    print(\"Shape of out :\", out.shape)      # [B, num_classes]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GycmS4Mo5KA-",
        "outputId": "b8271ef8-9cbd-4c20-bd2a-f3f3e70bda4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable Parameters: 4.328M\n",
            "Shape of out : torch.Size([1, 100])\n"
          ]
        }
      ]
    }
  ]
}